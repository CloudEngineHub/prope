<!doctype html>
<html lang="en">

<head>
  <!-- Meta tags -->
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <!-- HTML Meta Tags -->
  <title>Cameras as Relative Position Encoding</title>
  <meta name="description" content="Cameras as Relative Position Encoding" />
  <meta property="og:image" content="./assets/teaser_static.png" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="1704" />
  <meta property="og:image:height" content="636" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://www.liruilong.cn/prope/" />
  <meta property="og:title" content="Cameras as Relative Position Encoding" />
  <meta property="og:description"
    content="We introduce PRoPE, a method for conditioning image tokens based on corresponding camera parameters in transformers for multiview vision tasks." />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Cameras as Relative Position Encoding" />
  <meta name="twitter:description"
    content="We introduce PRoPE, a method for conditioning image tokens based on corresponding camera parameters in transformers for multiview vision tasks." />
  <meta name="twitter:image" content="./assets/teaser_static.png" />
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous" />
  <link href="https://fonts.googleapis.com/css?family=Lato|Varela+Round|Open+Sans" rel="stylesheet" type="text/css" />
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ“·</text></svg>" />
  <!-- Bootstrap JS -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
    crossorigin="anonymous"></script>
  <!-- Customized style -->
  <style>
    html * {
      color: #333;
      font-family: "Lato", sans-serif;
    }

    .terminal-container {
      position: relative;
      border-radius: 18px;
      box-shadow: 0 8px 32px 0 #1a1a1a44, 0 1.5px 16px 0 #223c5b24;
      background: rgba(0, 0, 0, 0.9);
      border: 1.6px solid rgba(222, 220, 245, 0.13);
      width: 100%;
      max-width: 1000px;
      margin: 0 auto;
      padding: 0 0 2.3rem 0;
    }

    .terminal-header {
      display: flex;
      align-items: center;
      height: 44px;
      border-radius: 18px 18px 0 0;
      padding: 0.35em 1.1em;
      background: rgba(80, 80, 80, 0.9);
      border-bottom: 1.2px solid rgba(222, 220, 245, 0.11);
      user-select: none;
      font-family: inherit;
      position: relative;
      justify-content: center;
      font-size: 1.2em;
    }

    .mac-controls {
      display: flex;
      gap: 0.7em;
      margin-right: auto;
      margin-left: 0;
      margin-top: 2px;
      z-index: 2;
    }

    .mac-dot {
      width: 16px;
      height: 16px;
      border-radius: 50%;
      display: inline-block;
      box-shadow: 0 0 2px #0002;
      border: 1px solid #0002;
    }

    .mac-dot.red {
      background: #ff5f56;
    }

    .mac-dot.yellow {
      background: #ffbd2e;
    }

    .mac-dot.green {
      background: #27c93f;
    }

    .terminal-content {
      padding: 1.5rem 1.0rem 1.0rem 1.0rem;
      border-radius: 0 0 18px 18px;
      min-height: 3em;
      box-sizing: border-box;
      font-size: 0.8em;
      color: #fff;
      overflow: visible;
    }

    pre {
      background: none !important;
      box-shadow: none !important;
      margin: 0;
      padding: 0;
      border: none;
      width: 100%;
      font-size: inherit;
      overflow: visible;
    }

    code {
      background: none !important;
      box-shadow: none !important;
      font-family: 'JetBrains Mono', 'Fira Mono', 'Menlo', monospace;
      font-size: 0.65em;
      line-height: 1.6;
      white-space: pre-wrap;
      width: 100%;
      display: block;
      min-height: 3em;
      box-sizing: border-box;
      color: #FFFFFF !important;
      text-align: left;
      padding-left: 1rem;
    }

    /* Override highlight.js styles to use same font */
    .hljs-comment,
    .hljs-keyword,
    .hljs-string,
    .hljs-number,
    .hljs-function,
    .hljs-title,
    .hljs-params,
    .hljs-literal,
    .hljs-operator,
    .hljs-punctuation {
      font-family: 'JetBrains Mono', 'Fira Mono', 'Menlo', monospace !important;
    }

    .cursor {
      display: inline-block;
      width: 1ch;
      height: 1.1em;
      vertical-align: text-bottom;
      margin-left: 1px;
      border-radius: 2px;
      background: #fff7;
      animation: blink 0.85s infinite steps(1);
      box-shadow: 0 0 0.5px #fff8;
    }

    @keyframes blink {
      50% {
        background: transparent;
      }
    }

    table.results td {
      color: #888;
      font-size: 90%;
    }

    .mtitle {
      margin-top: 0;
      font-family: "Varela Round", sans-serif;
      color: #000000;
      font-size: 42px;
      line-height: 60px;
      font-weight: 600;
      letter-spacing: 1px;
    }

    .msubtitle {
      margin-top: -30px;
      margin-bottom: -20px;
      font-size: 23px;
      line-height: 65px;
      letter-spacing: 2px;
    }

    .mneurips {
      margin-top: 10px;
      margin-bottom: 10px;
      color: #aaa;
      font-size: 25px;
    }

    .mauthors {
      font-size: 20px;
      font-weight: 400;
      line-height: 15px;
    }

    .mauthors_affiliation {
      margin-top: -12px;
      margin-bottom: 24px;
      font-family: "Open Sans", sans-serif;
      font-size: 20px;
      line-height: 15px;
    }

    .mauthors_affiliation_reference {
      margin-top: -12px;
      margin-bottom: 24px;
      font-family: "Open Sans", sans-serif;
      font-size: 16px;
      line-height: 15px;
    }

    .darker_bg {
      padding-top: 32px;
      padding-bottom: 32px;
      background-color: #f5f5f5;
    }

    .nav-link {
      color: #333;
    }

    .nav-link a:hover,
    a:hover,
    a:active {
      color: #888 !important;
    }

    .accordion-button:not(.collapsed) {
      color: inherit;
      background: #f5f5f5;
    }

    .accordion-button:not(.collapsed)::after {
      filter: brightness(0%) invert(70%);
    }

    .accordion-button:focus {
      box-shadow: inherit;
    }
  </style>
</head>

<body>
  <a href="https://github.com/liruilong940607/prope" class="github-corner"
    aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="
          fill: #151513;
          color: #fff;
          position: absolute;
          top: 0;
          border: 0;
          right: 0;
        " aria-hidden="true">
      <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
      <path
        d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
        fill="#fff" style="transform-origin: 130px 106px" class="octo-arm"></path>
      <path
        d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
        fill="#fff" class="octo-body"></path>
    </svg></a>
  <style>
    .github-corner:hover .octo-arm {
      animation: octocat-wave 560ms ease-in-out;
    }

    @keyframes octocat-wave {

      0%,
      100% {
        transform: rotate(0);
      }

      20%,
      60% {
        transform: rotate(-25deg);
      }

      40%,
      80% {
        transform: rotate(10deg);
      }
    }

    @media (max-width: 500px) {
      .github-corner:hover .octo-arm {
        animation: none;
      }

      .github-corner .octo-arm {
        animation: octocat-wave 560ms ease-in-out;
      }
    }
  </style>
  <div class="container-fluid my-5 mx-auto" style="max-width: 840px">
    <div class="row">
      <!-- <h1 class="display-8 text-center msubtitle"></h1> -->
      <h1 class="display-12 text-center mtitle">
        Cameras as Relative Position Encoding
      </h1>
    </div>

    <div class="row mt-2">
      <div class="display-8 text-center mneurips">Arxiv 2025</div>
    </div>

    <div class="row text-center mt-3 mx-auto mauthors" style="max-width: 840px">
      <div style="flex: 0 0 15%;">
        <a href="https://www.liruilong.cn/"> Ruilong Li* </a>
      </div>
      <div style="flex: 0 0 15%;">
        <a href="https://brentyi.github.io/"> Brent Yi* </a>
      </div>
      <div style="flex: 0 0 17%;">
        <a href="https://junchenliu77.github.io/"> Junchen Liu* </a>
      </div>
      <div style="flex: 0 0 15%;">
        <a href="https://hangg7.com/"> Hang Gao </a>
      </div>
      <div style="flex: 0 0 13%;">
        <a href="https://people.eecs.berkeley.edu/~yima/"> Yi Ma </a>
      </div>
      <div style="flex: 0 0 25%;">
        <a href="https://people.eecs.berkeley.edu/~kanazawa/"> Angjoo Kanazawa </a>
      </div>
    </div>

    <div class="row text-center mt-2 mx-auto mauthors_affiliation_reference" style="max-width: 840px">
      <div style="flex: 0 0 15%;">
        [1, 2]
      </div>
      <div style="flex: 0 0 15%;">
        [1]
      </div>
      <div style="flex: 0 0 17%;">
        [1]
      </div>
      <div style="flex: 0 0 15%;">
        [1]
      </div>
      <div style="flex: 0 0 13%;">
        [1, 3]
      </div>
      <div style="flex: 0 0 25%;">
        [1]
      </div>
    </div>

    <div class="row text-center mt-0 mx-auto mauthors_affiliation" style="max-width: 840px">
      <div style="flex: 0 0 33%;">
        [1] UC Berkeley
      </div>
      <div style="flex: 0 0 33%;">
        [2] NVIDIA
      </div>
      <div style="flex: 0 0 33%;">
        [3] HKU
      </div>
    </div>

    <div class="row mt-2 text-center">
      <a class="nav-link col-3"></a>
      <a href="https://arxiv.org/abs/TODO:This should be the URL of the arxiv>" class="nav-link col-3">
        <svg style="width: 48px; height: 48px" viewBox="0 0 24 24">
          <path fill="currentColor"
            d="M16 0H8C6.9 0 6 .9 6 2V18C6 19.1 6.9 20 8 20H20C21.1 20 22 19.1 22 18V6L16 0M20 18H8V2H15V7H20V18M4 4V22H20V24H4C2.9 24 2 23.1 2 22V4H4M10 10V12H18V10H10M10 14V16H15V14H10Z" />
        </svg><br />
        Paper
      </a>
      <a href="https://github.com/liruilong940607/prope" class="nav-link col-3">
        <svg style="width: 48px; height: 48px" viewBox="0 0 24 24">
          <path fill="currentColor"
            d="M12,2A10,10 0 0,0 2,12C2,16.42 4.87,20.17 8.84,21.5C9.34,21.58 9.5,21.27 9.5,21C9.5,20.77 9.5,20.14 9.5,19.31C6.73,19.91 6.14,17.97 6.14,17.97C5.68,16.81 5.03,16.5 5.03,16.5C4.12,15.88 5.1,15.9 5.1,15.9C6.1,15.97 6.63,16.93 6.63,16.93C7.5,18.45 8.97,18 9.54,17.76C9.63,17.11 9.89,16.67 10.17,16.42C7.95,16.17 5.62,15.31 5.62,11.5C5.62,10.39 6,9.5 6.65,8.79C6.55,8.54 6.2,7.5 6.75,6.15C6.75,6.15 7.59,5.88 9.5,7.17C10.29,6.95 11.15,6.84 12,6.84C12.85,6.84 13.71,6.95 14.5,7.17C16.41,5.88 17.25,6.15 17.25,6.15C17.8,7.5 17.45,8.54 17.35,8.79C18,9.5 18.38,10.39 18.38,11.5C18.38,15.32 16.04,16.16 13.81,16.41C14.17,16.72 14.5,17.33 14.5,18.26C14.5,19.6 14.5,20.68 14.5,21C14.5,21.27 14.66,21.59 15.17,21.5C19.14,20.16 22,16.42 22,12A10,10 0 0,0 12,2Z" />
        </svg><br />
        &#60;/Code&#62;
      </a>
      <!-- <a href="https://drive.google.com/drive/folders/TODO:This should be the URL of the data/checkpoints>"
        class="nav-link col-2">
        <svg style="width: 48px; height: 48px" viewBox="0 0 24 24">
          <path fill="currentColor"
            d="M12,3C7.58,3 4,4.79 4,7C4,9.21 7.58,11 12,11C16.42,11 20,9.21 20,7C20,4.79 16.42,3 12,3M4,9V12C4,14.21 7.58,16 12,16C16.42,16 20,14.21 20,12V9C20,11.21 16.42,13 12,13C7.58,13 4,11.21 4,9M4,14V17C4,19.21 7.58,21 12,21C16.42,21 20,19.21 20,17V14C20,16.21 16.42,18 12,18C7.58,18 4,16.21 4,14Z" />
        </svg><br />
        Data
      </a>
      <a class="nav-link col-3"></a> -->
    </div>

    <div class="row">
      <div class="col-md-12 mt-2">
        <center>
          <img src="assets/teaser_static_long.png" alt="teaser" style="width: 100%;">
        </center>
      </div>
    </div>

    <div class="my-5">
      <h3 class="mt-4 mb-3">Problem: Camera Conditioning in Multi-view Transformers</h3>
      <p>
        As transformers become increasingly prevalent in multi-view 3D perception, a central
        challenge is effectively incorporating the input camera parameters to ground
        visual observations in 3D space.
      </p>
      <div class="row">
        <div class="col-md-12 mt-2">
          <center>
            <video width="100%" autoplay loop muted playsinline>
              <source src="assets/multiview-transformer-720P.mp4" type="video/mp4" />
            </video>
          </center>
        </div>
      </div>
    </div>

    <div class="my-5">
      <h3 class="mt-4 mb-3">Idea: Camera as Image's "Positional" Identifier</h3>
      <p>
        The camera, defined by its intrinsic and extrinsic parameters, uniquely determines
        where and how the image observation was captured within the 3D world,
        acting as the "positional" identifier that we aim to spatially encode into the
        multi-view transformer.
      </p>
      <div class="row">
        <div class="col-md-12 mt-2">
          <table width="100%" class="results">
            <tr align="center">
              <td width="50%">
                <video width="100%" autoplay loop muted controls>
                  <source src="./assets/2d-obs-2-down2x.mp4" type="video/mp4" />
                </video>
              </td>
              <td width="50%">
                <video width="100%" autoplay loop muted controls>
                  <source src="./assets/2d-obs-1-down2x.mp4" type="video/mp4" />
                </video>
              </td>
            </tr>
            <tr align="center">
              <td>2D Observations</td>
              <td>Camera: {intrinsic, extrinsic}</td>
            </tr>
          </table>
        </div>
      </div>
    </div>

    <div class="my-5">
      <h3 class="mt-4 mb-3">Positional Encoding for Multi-view Geometry</h3>
      <p>
        Geometric relationships are important for visual tokens in multiview transformers. This is similar to 1D
        position in large language models,
        where relative position encodings (RPEs) can capture token-to-token distances. The relationships that matter in
        multiview geometry
        are between cameras, which can be fully specified by intrinsic and extrinsic parameters:
      </p>
      <div class="row">
        <div class="col-md-12 mt-2">
          <center>
            <img src="assets/placeholder_rpe.png" alt="teaser" style="width: 100%;">
          </center>
        </div>
      </div>
    </div>

    <div class="my-5">
      <h3 class="mt-4 mb-3">Our Method: Relative Projective Positional Encoding (PRoPE)</h3>
      <p>
        In its essence, PRoPE explicitly encodes the relative camera <em>projective</em>
        transformation between tokens -- in an RoPE-like manner -- which is compatible
        with flash-attention and brings little overhead to the system.
      </p>
      <div class="row">
        <div class="col-md-12 mt-2">
          <center>
            <img src="assets/formulation_pij.png" alt="teaser" style="width: 50%;">
          </center>
        </div>
      </div>

      <p>
        It is also extremely easy to implement and can be plugged
        into any existing attention-based framework with minimal changes: Just replace
        the `F.scaled_dot_product_attention` with the code snippet below to inject
        camera information.
      </p>
      <div class="row">
        <div class="col-md-12 mt-2">
          <center>
            <div class="terminal-container">
              <div class="terminal-header">
                <span class="mac-controls">
                  <span class="mac-dot red"></span>
                  <span class="mac-dot yellow"></span>
                  <span class="mac-dot green"></span>
                </span>
              </div>
              <div class="terminal-content">
                <pre><code id="typing-area" class="language-python"></code></pre>
              </div>
            </div>
          </center>
        </div>
      </div>
    </div>


    <div class="row my-5">
      <h3 class="mt-4 mb-3">Plug-and-Play: Improved Novel View Synthesis</h3>
      <p>
        We inject PRoPE into the existing LVSM framework and evaluate its performance on the
        task of novel view synthesis.
      </p>
      <nav>
        <div class="nav nav-tabs" id="nav-tab" role="tablist">
          <button class="nav-item nav-link active" id="tab-tele-lvsm-train" data-bs-toggle="tab"
            data-bs-target="#video-tele-lvsm-train" role="tab" type="button" aria-controls="tab-tele-lvsm-train"
            aria-selected="true">
            Training Curves
          </button>
          <button class="nav-item nav-link" id="tab-tele-lvsm-eval" data-bs-toggle="tab"
            data-bs-target="#video-tele-lvsm-eval" role="tab" type="button" aria-controls="tab-tele-lvsm-eval"
            aria-selected="false">
            Evaluation Curves
          </button>
          <button class="nav-item nav-link" id="tab-tele-lvsm-visual" data-bs-toggle="tab"
            data-bs-target="#video-tele-lvsm-visual" role="tab" type="button" aria-controls="tab-tele-lvsm-visual"
            aria-selected="false">
            Visual Comparison
          </button>
        </div>
      </nav>
      <div class="tab-content" id="nav-tabContent">
        <div class="tab-pane fade show active text-center" id="video-tele-lvsm-train" role="tabpanel"
          aria-labelledby="tab-tele-lvsm-train" style="background-color: white">
          <table width="100%" class="results">
            <tr align="center">
              <video width="100%" autoplay loop muted controls>
                <source src="./assets/LVSM_Train.mp4" type="video/mp4" />
              </video>
            </tr>
          </table>
        </div>
        <div class="tab-pane fade text-center" id="video-tele-lvsm-eval" role="tabpanel"
          aria-labelledby="tab-tele-lvsm-eval" style="background-color: white">
          <table width="100%" class="results">
            <tr align="center">
              <video width="100%" autoplay loop muted controls>
                <source src="./assets/LVSM_Eval.mp4" type="video/mp4" />
              </video>
            </tr>
          </table>
        </div>
        <div class="tab-pane fade text-center" id="video-tele-lvsm-visual" role="tabpanel"
          aria-labelledby="tab-tele-lvsm-visual" style="background-color: white">
          <table width="100%" class="results">
            <tr align="center">
              <td width="50%">
                <video width="100%" autoplay loop muted controls>
                  <source src="./assets/visuals/lvsm-plucker-none-test-zoom3x-0387ef3895b1393c.mp4" type="video/mp4" />
                </video>
              </td>
              <td width="50%">
                <video width="100%" autoplay loop muted controls>
                  <source src="./assets/visuals/lvsm-plucker-prope-test-zoom3x-0387ef3895b1393c.mp4" type="video/mp4" />
                </video>
              </td>
            </tr>
            <tr align="center">
              <td>LVSM</td>
              <td>LVSM + PRoPE</td>
            </tr>
          </table>
        </div>
      </div>
    </div>


    <div class="row my-5">
      <h3 class="mt-4 mb-3">Plug-and-Play: Improved Stereo Depth Estimation</h3>
      <p>
        We inject PRoPE into the official UniMatch codebase and evaluate its performance on the
        task of stereo depth estimation.
      </p>
      <nav>
        <div class="nav nav-tabs" id="nav-tab" role="tablist">
          <button class="nav-item nav-link active" id="tab-tele-unimatch-train" data-bs-toggle="tab"
            data-bs-target="#video-tele-unimatch-train" role="tab" type="button" aria-controls="tab-tele-unimatch-train"
            aria-selected="true">
            Training Curves
          </button>
          <button class="nav-item nav-link" id="tab-tele-unimatch-eval" data-bs-toggle="tab"
            data-bs-target="#video-tele-unimatch-eval" role="tab" type="button" aria-controls="tab-tele-unimatch-eval"
            aria-selected="false">
            Evaluation Curves
          </button>
          <button class="nav-item nav-link" id="tab-tele-unimatch-visual" data-bs-toggle="tab"
            data-bs-target="#video-tele-unimatch-visual" role="tab" type="button"
            aria-controls="tab-tele-unimatch-visual" aria-selected="false">
            Visual Comparison
          </button>
        </div>
      </nav>
      <div class="tab-content" id="nav-tabContent">
        <div class="tab-pane fade show active text-center" id="video-tele-unimatch-train" role="tabpanel"
          aria-labelledby="tab-tele-unimatch-train" style="background-color: white">
          <table width="100%" class="results">
            <tr align="center">
              <video width="100%" autoplay loop muted controls>
                <source src="./assets/UniMatch_Train.mp4" type="video/mp4" />
              </video>
            </tr>
          </table>
        </div>
        <div class="tab-pane fade text-center" id="video-tele-unimatch-eval" role="tabpanel"
          aria-labelledby="tab-tele-unimatch-eval" style="background-color: white">
          <table width="100%" class="results">
            <tr align="center">
              <video width="100%" autoplay loop muted controls>
                <source src="./assets/UniMatch_Eval.mp4" type="video/mp4" />
              </video>
            </tr>
          </table>
        </div>
        <div class="tab-pane fade text-center" id="video-tele-unimatch-visual" role="tabpanel"
          aria-labelledby="tab-tele-unimatch-visual" style="background-color: white">
          <table width="100%" class="results">
            <tr align="center">
              <td width="50%">
                <img src="assets/visuals/unimatch.png" alt="unimatch" style="width: 100%;">
              </td>
              <td width="50%">
                <img src="assets/visuals/unimatch-prope.png" alt="unimatch-prope" style="width: 100%;">
              </td>
            </tr>
            <tr align="center">
              <td>UniMatch</td>
              <td>UniMatch + PRoPE</td>
            </tr>
          </table>
        </div>
      </div>
    </div>


    <div class="my-5">
      <h3 class="mt-4 mb-3">Better Robostness than Alternative Camera Conditioning Methods</h3>
      <p>
        Our method demonstrates superior robustness on handling out-of-distribution context
        length (more views) and out-of-distribution intrinsic parameters (zoom-in) at test time,
        benefiting from our <em>relative</em> camera encoding formula.
      </p>
      <div class="row">
        <div class="col-md-12 mt-2">
          <table width="100%" class="results">
            <center>
              <img src="assets/ood-combined.png" alt="ood-combined" style="width: 95%;">
            </center>
          </table>
        </div>
      </div>
    </div>


    <!-- <p style="color: red;">
      TODO: More results
    </p> -->

    <!-- <div class="row my-5">
      <h2>Citation</h2>
      <div class="col-md-12 mt-3">
        <pre><code>
@inproceedings{}</code>
      </pre>
      </div>
    </div> -->

    <!-- <div class="my-5">
      <h2>Acknowledgement</h2>
      <p>
      </p>
    </div> -->

    <div class="text-center">
      <hr />
      <small>Website inspired by
        <a href="https://kair-bair.github.io/dycheck/">DyCheck</a>
      </small>
    </div>
    
  </div>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/night-owl.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>
  <script>
    const code = `def prope_dot_product_attention(q, k, v, extrinsics, intrinsics, image_width, image_height):
      # Compute projective matrix: K [R | t]
      intrinsics = normalize_intrinsics(intrinsics, image_width, image_height)
      P = lift_K(intrinsics) @ extrinsics 
      
      # Block-diagonal transforms to the inputs and outputs of the attention operator.
      fn_q = [(partial(_apply_projmat, P.t()), D // 2), (partial(_apply_rope), D // 2)]
      fn_kv = [(partial(_apply_projmat, P.inverse()), D // 2), (partial(_apply_rope), D // 2)]
      fn_o = [(partial(_apply_projmat, P), D // 2), (partial(_apply_rope, inverse=True), D // 2)]
      o = F.scaled_dot_product_attention(
          query=_apply_block_diagonal(q, fn_q),
          key=_apply_block_diagonal(k, fn_kv),
          value=_apply_block_diagonal(v, fn_kv),
      )
      return _apply_block_diagonal(o, fn_o)`;

    const typingArea = document.getElementById('typing-area');
    const typeSpeed = 8; // Faster typing speed
    let hasTyped = false; // Prevent multiple animations

    async function typeText(target, text) {
      if (hasTyped) return; // Don't type again if already done
      hasTyped = true;

      for (let i = 0; i <= text.length; ++i) {
        const curr = text.slice(0, i);
        target.innerHTML = hljs.highlight(curr, { language: 'python' }).value + '<span class="cursor"></span>';
        await new Promise(r => setTimeout(r, typeSpeed));
      }
    }

    // Use Intersection Observer to start typing when section comes into view
    const observer = new IntersectionObserver((entries) => {
      entries.forEach(entry => {
        if (entry.isIntersecting && !hasTyped) {
          typeText(typingArea, code);
        }
      });
    }, {
      threshold: 0.3 // Start when 30% of the element is visible
    });

    // Start observing when page loads
    window.addEventListener('load', () => {
      const terminalContainer = document.querySelector('.terminal-container');
      if (terminalContainer) {
        observer.observe(terminalContainer);
      }
    });
  </script>
</body>

</html>
